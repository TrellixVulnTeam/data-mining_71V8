{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "# Data Mining and Decision Systems ACW\n",
    "<br></br>\n",
    "#### Student number: 201601628\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Notebook Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Package Imports\n",
    "Import all libraries/packages used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from sklearn import model_selection, linear_model, svm\n",
    "# from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, confusion_matrix, plot_confusion_matrix\n",
    "# from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "# from sklearn.neural_network import MLPClassifier as mlp\n",
    "# from sklearn.ensemble import RandomForestClassifier as rf\n",
    "# from sklearn.feature_selection import SelectFromModel ## https://chrisalbon.com/machine_learning/trees_and_forests/feature_selection_using_random_forest/\n",
    "# from sklearn.model_selection import StratifiedKFold ## https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n",
    "\n",
    "# from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "from collections import defaultdict ## Used in automating and collating data discrepancies.\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Data Loading\n",
    "Read in the file containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data.csv\" ## Relative path to train/test data.\n",
    "rawData = pd.read_csv(path) ## Original data to make copies from and compare with.\n",
    "rawData.head(3) ## Show dataframe to check it was read correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance it can be seen that all column headers are unique, so for the sake of simplicity and to avoid trivial errors, convert them to lowercase.\n",
    "\n",
    "**NB:** all other modifications will be made to copies of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData.columns = [col.lower() for col in rawData.columns] ## Make headers lowercase to avoid some trivial errors.\n",
    "rawData.head(3) ## Show dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Utility Functions\n",
    "Define any utility functions or properties used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawNRows = rawData.shape[0] ## Get number of rows in original dataframe.\n",
    "rawNCols = rawData.shape[1] ## Get number of columns in original dataframe.\n",
    "rawColNames = rawData.columns.values # Get column names which will often be used as an iterator.\n",
    "# concerns = defaultdict(list) ## Create a dict to store data discrepencies without littering notebook with outputs until required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For pretty printing.\n",
    "# ''' n == number of indents '''\n",
    "def Indent(n=1):\n",
    "    indentSize = 4\n",
    "    indent = (\" \" * indentSize) * n\n",
    "    return indent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iterate over dictionary items and output the key and any values.\n",
    "# ''' collection == dictionary object '''\n",
    "# ''' label == string to prefix each dictionary key e.g. \"1. \" '''\n",
    "def PrintDict(collection, label = \"\"):\n",
    "    i = 1\n",
    "    for key, value in collection.items():\n",
    "        print(\"\\n________________________________________________________________\\n\")  \n",
    "        print(label + str(i) + \": \" + key)\n",
    "        i += 1\n",
    "\n",
    "        for val in value:\n",
    "            print(val)\n",
    "    \n",
    "    print(\"\\n________________________________________________________________\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute a value in a given record based on the mode in a collection, using the knowledge that\n",
    "## the data set is quite homogenous.\n",
    "# ''' toImpute == feature to impute '''\n",
    "# ''' record == pd series object '''\n",
    "# ''' df == pd dataframe object '''\n",
    "# ''' ignore == list of columns to ignore '''\n",
    "# ''' output == bool : True = print result '''\n",
    "def NNImpute(toImpute, record, df, ignore=[], output=True):\n",
    "    neighbours = []\n",
    "    \n",
    "    # Look for records that are duplicated when ignoring the specifed columns and target feature.\n",
    "    ignore.append(toImpute)\n",
    "    tempDf = df.drop(columns=ignore)\n",
    "    tempSeries = record.drop(labels=ignore)\n",
    "\n",
    "    for index, row in tempDf.iterrows():\n",
    "        if row.all() == tempSeries.all():\n",
    "            neighbours.append(index)\n",
    "    \n",
    "    # Get the mode class of the neighbours.\n",
    "    mode = df.iloc[neighbours][toImpute].mode()[0]\n",
    "    \n",
    "    if output:\n",
    "        print(\"Based on \" + str(len(neighbours)) + \" neighbours: \" + str(mode))\n",
    "    \n",
    "    return mode    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# CRISP DM\n",
    "Herein, the CRISP DM data methodology is followed (as close as is possible in the context of this project).\n",
    "\n",
    "<img src=\"crisp-dm.png\" style=\"max-height:300px\">\n",
    "\n",
    "Most time is spent in the 'Data Understanding' phase to make up for the fact that there is no client communcation beyond the given information and to allow for better informed decisions in the 'Data Preperation' and 'Modelling' stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Business Understanding\n",
    "Beyond the the given task definition and data dictionary, there will be no additional client/business communication. Therefore, some assumptions must be made based on *personal*: experience, domain knowledge, and research.\n",
    "\n",
    " <hr>\n",
    "\n",
    "**Below is a brief breakdown** of the problem definition and some domain considerations:\n",
    "\n",
    "DOMAIN: Cardio-vascular medicine / healthcare\n",
    "\n",
    "- As a healthcare dataset it may be \"natural\", anonymised patient data, study data (e.g. clinical trial), or an aggregation of many different datasets.\n",
    "- There is a chance there is \"control\" data (healthy cohorts) within the dataset or, similarly, focus groups that consist of unhealthy cohorts.\n",
    "- Due to the (often) subjective nature of clinical diagnosis (i.e. different doctors with varying levels of experience make the diagnoses), some data may be mislabelled.\n",
    "- Some diagnoses or features may be self-certified or be derived from incorrect patient interpretations (e.g. \"Yes, I have been feeling...\").\n",
    "- Some features might represent the same thing (e.g. an alternative clincal test - both may be conducted or one might replace the other). \n",
    "\n",
    "PROBLEM TYPE: Classification\n",
    "\n",
    "INPUTS: Tabulated patient data; (up-to) 1520 records of 11 features\n",
    "\n",
    "OUTPUTS:\n",
    "- Risk\n",
    "- No Risk\n",
    "\n",
    "<hr>\n",
    "\n",
    "**More objectively**, domain-specific terminology from the provided data dictionary can be researched further:\n",
    "\n",
    "- Atrial Fibrillation\n",
    "    - A form of **arrythmia** (Atrial Fibrillation and other Arrhythmias, 2019).\n",
    "    - Increases risk of stroke (https://www.nhs.uk/conditions/arrhythmia/)\n",
    "    \n",
    "    \n",
    "- Asymptomatic Stenosis\n",
    "    - Narrowing of the cartoid artery without recent history of TIA  or ischemic stroke (https://www.uptodate.com/contents/management-of-asymptomatic-carotid-atherosclerotic-disease).\n",
    "\n",
    "\n",
    "- Cardiovascular Arrest\n",
    "    - When the heart stops pumping blood - NOT a heart attack (https://www.bhf.org.uk/informationsupport/conditions/cardiac-arrest).\n",
    "    - Can be caused by arrhythmias (https://www.heart.org/en/health-topics/cardiac-arrest/about-cardiac-arrest).\n",
    "    \n",
    "    \n",
    "- Transient Ischemic Attack (mini heart attack)\n",
    "    - Risk increased by a-f, asx, diabetes and hypertension (https://www.nhs.uk/conditions/transient-ischaemic-attack-tia/; https://www.cardiosmart.org/Healthwise/hw22/6606/hw226606).\n",
    "    - Actually a **mini-stroke**, not heart attack.\n",
    "\n",
    "\n",
    "- Diabetes\n",
    "    - Type 2 makes up 90% of cases, but could be type 1 or a mix of both (https://www.bhf.org.uk/informationsupport/risk-factors/diabetes).\n",
    "\n",
    "\n",
    "- IHD/CAD (Ischemic Heart Disease/Coronary Artery Disease)\n",
    "    - Narrowing or blockage of the coronary arteries (https://www.cancer.gov/publications/dictionaries/cancer-terms/def/coronary-heart-disease).\n",
    "\n",
    "\n",
    "- Hypertension\n",
    "    - i.e high blood pressure.\n",
    "\n",
    "\n",
    "- Arrhythmia (erratic heart beat)\n",
    "    - Main types include **a-f**, tachcardia, bradycardia heart block and ventricular fibrilation (may cause cardiac arrest) (https://www.nhs.uk/conditions/arrhythmia/).\n",
    "\n",
    "\n",
    "- IPSI (ipsilateral cerebral ischemic lesions)\n",
    "    - Ipsilateral means \"same side\". Based on the context, the side of comparsion is likely the side of the brain that the stroke occurred.\n",
    "\n",
    "\n",
    "- Contra (contralateral cerebral ischemic lesions)\n",
    "    - Contralateral means \"opposite side\". Based on the context, the side of comparsion is likely the side of the brain that the stroke occurred.\n",
    "\n",
    "\n",
    "- (History) Cardiovascular Interventions\n",
    "    - Typically, cardiac invasive treatments e.g. catheterisation. (https://onlinelibrary.wiley.com/doi/book/10.1002/9781444316704)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Based on these findings**, there are some assumptions to be made:\n",
    "\n",
    "- Patients with an indication of \"a-f\" should also be be recorded as having an arrhythmia.\n",
    "\n",
    "\n",
    "- The indication feature almost appears ordinal, with a-f and asx being cause for cva and tia; although it is difficult to verify this without communicating with professionals.\n",
    "\n",
    "\n",
    "- Assuming IPSI and Contra are recorded at the same time in relation to the same stroke or event; and Since IPSI is reffering to the percentage of lesions on the same side and Contra on the opposite side, it would make sense for the 2 values to have sum of 100%\n",
    "\n",
    "<hr>\n",
    "\n",
    "*References*\n",
    "\n",
    "    - 1\n",
    "    \n",
    "    - 2\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Understanding\n",
    "This section focuses on an in-depth understanding of the given date, its correctness and any patterns.\n",
    "<hr>\n",
    "\n",
    "## 2.1. Data Dictionary\n",
    "The data dictionary with all expected features and their format is included in the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p><strong>Attribute</strong></p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p><strong>Value Type</strong></p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p><strong>NumberOfValues</strong></p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p><strong>Values</strong></p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p><strong>Comment</strong></p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p><strong>Non-clinical Description</strong></p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>Random</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Real</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Number of Records</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Unique</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Real number of help in randomly sorting the data records</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Real number of&nbsp;help&nbsp;in randomly sorting the data records: Should be unique values.</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>Id</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Integer</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Max of Number of Records</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Unique to patient</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Anonymous patient record identifier: Should be unique values unless patient has multiple sessions</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Anonymous patient record identifier: Should be unique value per patient. Patient can have multiple sessions</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>Indication</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Nominal</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Four</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>{a-f, asx, cva, tia}</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>What type of Cardiovascular event triggered the hospitalisation?</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>What type of Cardiovascular event triggered the hospitalisation?</p><p> a-f :&nbsp;Atrial-Fibrillation</p>\n",
    "                <p>asx&nbsp;:&nbsp;Asymptomatic Stenosis&nbsp;</p><p>cva&nbsp;: Cardiovascular Arrest</p>\n",
    "                <p>tia&nbsp;:&nbsp;Transient Ischemic Attack (\"mini-heart attack\")</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>Diabetes</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Nominal</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Two</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>{no, yes}</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Does the patient suffer from Diabetes?</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Does the patient suffer from Diabetes?</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>IHD</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Nominal</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Two</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>{no, yes}</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Does the patient suffer from Coronary artery disease (CAD), also known as ischemic heart disease (IHD)?</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Does the patient suffer from Coronary artery disease (CAD), also known as ischemic heart disease (IHD)?</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>Hypertension</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Nominal</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Two</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>{no, yes}</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Does the patient suffer from Hypertension?</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Does the patient suffer from Hypertension?</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>Arrhythmia</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Nominal</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Two</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>{no, yes}</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Does the patient suffer from</p>\n",
    "                <p>Arrhythmia (i.e. erratic heart beat)?</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Does the patient suffer from Arrhythmia (i.e. erratic&nbsp;heart beat)?</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>History</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Nominal</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Two</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>{no, yes}</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Has the patient a history of</p>\n",
    "                <p>Cardiovascular interventions?</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Has the patient a history of Cardiovascular interventions?</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>IPSI</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Integer</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Potentially 101</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>[0, 100]</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Percentage figure for cerebral ischemic lesions defined as ipsilateral</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Percentage figure for cerebral ischemic lesions defined as ipsilateral</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>Contra</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Integer</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Potentially 101</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>[0, 100]</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Percentage figure for contralateral cerebral ischemic lesions</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Percentage figure for contralateral cerebral ischemic lesions</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>Label</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Nominal</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Two</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>{risk, norisk}</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Is the patient at risk (Mortality)?</p>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Is the patient at risk (Mortality)?</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "    </tbody>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b style=\"color: red;\">NOTE:</b> \"Session\" is also included in the non-clinical description, but not included in the data dictionary.\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p><strong>Attribute</strong></p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p><strong>Value Type</strong></p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p><strong>NumberOfValues</strong></p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p><strong>Values</strong></p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p><strong>Comment</strong></p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p><strong>Non-clinical Description</strong></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p>Session</p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p>Unknown</p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p>Max Number of Records (assumed)</p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p>Unique to patient</p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p>Unknown</p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p>Anonymous patient session identifier.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at the data dictionary** it can be seen that the \"Random\" and \"Id\" attributes are supposed to be unique. If this is true, the features should provide almost no benefit to any models and can be discarded to reduce the dimensionality of the problem.\n",
    "\n",
    "The **Label** feature is the feature we want to predict and our ground-truth.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Data Correctness\n",
    "Check for data conformity to data dictionary and explore common pitfalls (e.g. missing or duplicate data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 2.2.1. Conformity to Data Dictionary\n",
    "The data dictionary serves as the foundation for assumptions made regarding the data.\n",
    "\n",
    "The following python-object is a distillation of the data-dictionary which can be used to check the expected values/types etc. against the *actual* data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Object description:\n",
    "# key == column/feature name.\n",
    "# nVals == range of expected values for a continuous column.\n",
    "# vals == possible values for any categoric or discrete column.\n",
    "\n",
    "assumptions = {\n",
    "    \"random\":{ ## Col name.\n",
    "        \"nVals\": (rawNRows, rawNRows), # Range: unique per record. ## Real.\n",
    "    },  \n",
    "    \"id\":{\n",
    "        \"nVals\": (1, rawNRows), ## Range: unique per patient. ## Integer.\n",
    "    },\n",
    "    \"indication\":{\n",
    "        \"vals\": [\"a-f\",\"asx\",\"cva\",\"tia\"] ## Possible values (except nan).\n",
    "    },\n",
    "    \"diabetes\":{\n",
    "        \"vals\": [\"yes\", \"no\"]\n",
    "    },\n",
    "    \"ihd\":{\n",
    "        \"vals\": [\"yes\", \"no\"]\n",
    "    },\n",
    "    \"hypertension\":{\n",
    "        \"vals\": [\"yes\", \"no\"]\n",
    "    },\n",
    "    \"arrhythmia\":{\n",
    "        \"vals\": [\"yes\", \"no\"]\n",
    "    },\n",
    "    \"history\": {\n",
    "        \"vals\": [\"yes\", \"no\"]\n",
    "    },\n",
    "    \"ipsi\": {\n",
    "        \"vals\": np.arange(0,101) # Percentage 0-100.\n",
    "    },\n",
    "    \"contra\": {\n",
    "        \"vals\": np.arange(0,101), # Percentage 0-100.\n",
    "    },\n",
    "    \"label\": {\n",
    "        \"vals\": [\"risk\", \"norisk\"]\n",
    "    },\n",
    "    \"session\":{ ## This feature was given separate to the dictionary.\n",
    "        \"nVals\": (1, rawNRows), ## Unique per patient (assumed).\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Compare Actual Data with Assumptions Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rawData.copy() # Copy of the unmodified, raw data.\n",
    "discrepancies = defaultdict(list) # Collate discrepencies.\n",
    "\n",
    "# Iterate over assumptions object.\n",
    "for key, value in assumptions.items():\n",
    "    \n",
    "    # If the expected feature exists in the actual data.\n",
    "    if key in rawColNames:\n",
    "        actualValues = df[key].dropna().unique() ## Ignore nan values in uniques (handle seperately).\n",
    "    \n",
    "        try:\n",
    "            # Check expected values.\n",
    "            expectedValues = value[\"vals\"]\n",
    "            if (not(set(actualValues) & set(expectedValues))):\n",
    "                discrepancies[\"EXPECTED VALUES\"].append(Indent(2) + key + \"\\n\" + Indent(3)+ \"Expected: \" + str(set(expectedValues)) + \"\\n\" + Indent(3)+ \"Actual: \" + str(set(actualValues)) + \"\\n\")\n",
    "        except:\n",
    "            # No \"vals\" key; value is expected to be unique (nVals).\n",
    "            actualNValues = len(actualValues)\n",
    "            expectedNValues = value[\"nVals\"]\n",
    "            if (not(actualNValues >= expectedNValues[0]) or not(actualNValues <= expectedNValues[1])): ## Check actual number of values is within the expected range.           \n",
    "                discrepancies[\"NUMBER OF UNIQUE VALUES\"].append(Indent(2) + key + \"\\n\" + Indent(3) + \"Expected: \" + str(expectedNValues) + \"\\n\" + Indent(3)+ \"Actual: \" + str(actualNValues))\n",
    "    else:\n",
    "        # Expected column isn't present.\n",
    "        discrepancies[\"MISSING COLUMNS\"].append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format and output any descrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintDict(discrepancies, \"Discrepancy \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "**Discrepancy 1: NUMBER OF UNIQUE VALUES**\n",
    "    \n",
    "- RANDOM was expected to be unique per patient, but only 1222 of 1520 records comply. Presumably, this can be attributed to null or duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"random\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of random attributes that aren't unique.\n",
    "nMissing = df[\"random\"].shape[0] - df[\"random\"].unique().shape[0]\n",
    "\n",
    "# Get number of random attributes that are duplicated or null.\n",
    "nDupes = df[df[\"random\"].duplicated() == True].shape[0] ## Get number of duplicate random attributes.\n",
    "nNan = df[df[\"random\"] == np.isnan].shape[0]\n",
    "\n",
    "# Calculate number of non-unique values not accounted for by nans and dupes.\n",
    "stillMissing = nMissing - (nDupes + nNan)\n",
    "\n",
    "print(str(nMissing) + \" values are not unique.\")\n",
    "print(str(nDupes) + \" 'random' values are duplicated.\")\n",
    "print(str(nNan) + \" 'random' values are nan.\")\n",
    "print (str(stillMissing) + \" non-unique records unaccounted for.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random feature isn't unique as as described in the data dictionary; there ae 298 duplicates.\n",
    "<p><b style=\"color: red\">ACTION:</b> The records where the random attributes are duplicated should be inspected further.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## View all duplicate values.\n",
    "randomDupes = df[df[\"random\"].duplicated(keep=False)]\n",
    "randomDupes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Records don't appear to be duplicated where the random attribute is duplicated and it is apparent that some random codes are duplicated more than once (e.g. indexes 1, 2 and 3).\n",
    "\n",
    "Considering the absence of the session column and the fact that the Id feature IS unique, it could be possible that the Id feature is actually the missing session column, and the random code is the patient id.\n",
    "\n",
    "To prove or disprove this, the following looks at each random code to see if any diabetes or history values change more than once per random code. If no such pattern is detected, this supports the idea that random is actually the patient id and the id is the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contradictions = []\n",
    "\n",
    "# Iterate through all the unique values in random.\n",
    "for randVal in df[\"random\"].unique():\n",
    "    \n",
    "    # Get the records with the current random value being inspected.\n",
    "    randDf = df[df[\"random\"] == randVal]\n",
    "    \n",
    "    try:\n",
    "        # See if the value for history changes more than once. \n",
    "        if randDf[\"history\"].value_counts()[\"yes\"] > 1:\n",
    "            contradictions.append(randVal)\n",
    "            continue\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # See if the value for diabetes changes more than once. \n",
    "        if randDf[\"diabetes\"].value_counts()[\"yes\"] > 1:\n",
    "            contradictions.append(randVal)\n",
    "            continue\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Report any contradictions.\n",
    "if len(contradictions) < 1:\n",
    "    print(\"No contradictions found.\")\n",
    "else:\n",
    "    contradictions ## Output list of random codes which disprove random being id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems possible that the random feature is actually a patient identifier and the id column is a unique identifier for the session.\n",
    "\n",
    "Arguments against this suggestion include the facts that values range between 0-1, which supports the concept of a sorting utility, and that the values in the id column are *very* unconventional for denoting sessions (expected values would be simpler, e.g. bl/baseline, 1/V1/V01).\n",
    "\n",
    "<p><b style=\"color: red\">ACTION:</b> Maintain the consideration that the random feature may be a patient identifier.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "**Discrepancy 2: EXPECTED VALUES**\n",
    "    \n",
    "- **INDICATION** had an unexpected variant of ASx/Asx. Clinical research also abbreviates the condition as \"ASX\" suggesting that they are the same class as stipulated by the data dictionary (https://www.sciencedirect.com/science/article/pii/S0741521415010241).\n",
    "    \n",
    "<p><b style=\"color: red\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ACTION:</b> Treat variations of \"asx\" as the same category.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These changes are fundamental, so best to work with them now.\n",
    "correctedData = rawData.copy()\n",
    "\n",
    "# Make all indication categories lowercase.\n",
    "correctedData[\"indication\"] = correctedData[\"indication\"].apply(lambda x: str(x).lower())\n",
    "correctedData[\"indication\"].unique() # Output and confirm changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- **CONTRA** is formatted as a string in the actual data, rather than the expected numeric format, although (with the exception of null values) the numeric equivalents are all within the expected range.\n",
    "\n",
    "<p><b style=\"color: red\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ACTION:</b> Convert contra values to numeric.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert empty strings to nan.\n",
    "correctedData['contra'] = correctedData['contra'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "# Convert all values to numeric.\n",
    "correctedData[\"contra\"] = correctedData[\"contra\"].apply(lambda x: float(x))\n",
    "correctedData[\"contra\"].head(3) # Output and confirm changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "- **LABEL** has an additional, unexpected category: \"Unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output all values where the value of the label feature equals \"Unknown\".\n",
    "correctedData[correctedData[\"label\"] == \"Unknown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the requested outputs of the end-product are risk and norisk, and the fact that there are only 2 of 1520 datapoints with this classification (overwhelming imbalance); they are useless.\n",
    "\n",
    "The options are to either impute the values, or drop them: although it isn't expected that either will have a significant effect since only 2 records are affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in correctedData[correctedData[\"label\"] == \"Unknown\"].index.values:\n",
    "    NNImpute(\"label\", correctedData.iloc[index], correctedData, ignore=[\"random\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checks = []\n",
    "\n",
    "for index in correctedData.index.values:\n",
    "    print(index)\n",
    "    imputed = NNImpute(\"label\", correctedData.iloc[index], correctedData, ignore=[\"random\", \"id\"], output=False)\n",
    "    actual = correctedData.iloc[index][\"label\"]\n",
    "    \n",
    "    if imputed != actual:\n",
    "        checks.append(index)\n",
    "        \n",
    "checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "dupes\n",
    "noDupes\n",
    "\n",
    "### Missing Data\n",
    "imputed\n",
    "dropped\n",
    "\n",
    "### Outliers\n",
    "imputeExpected (correct)\n",
    "drop\n",
    "\n",
    "### Other Assumptions\n",
    "Random, ID, Session\n",
    "drop or keep? clusterDf noClusterDf\n",
    "\n",
    "## Distribution\n",
    "### Univariate\n",
    "df.hist (low, default, high bins)\n",
    "    risk distribution (box plot)\n",
    "\n",
    "### Multivariate\n",
    "Check .corr and boxplot multiple features\n",
    "\n",
    "# 3. Data Preperation\n",
    "phase description\n",
    "\n",
    "## Cleaning\n",
    "\n",
    "## Transformation\n",
    "binarise\n",
    "1he/dummies\n",
    "\n",
    "## Feature Selection\n",
    "based on understanding\n",
    "aprioiri\n",
    "featureselection\n",
    "rf\n",
    "informed decision\n",
    "\n",
    "## Stratification\n",
    "tts\n",
    "stratified kfold\n",
    "!stratified kfold\n",
    "\n",
    "# 4. Modelling\n",
    "description\n",
    "\n",
    "Train CODE\n",
    "\n",
    "## Baseline (Multiple Linear Regression)\n",
    "foreach dataset, full featureset and selected features\n",
    "## SGD\n",
    "## SVM\n",
    "## K-Nearest Neighbours\n",
    "## Decision Tree\n",
    "## Random Forest\n",
    "## MLP\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "## Model Tuning\n",
    "\n",
    "# 5. Evaluation\n",
    "\n",
    "# 6. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisits:\n",
    "    \n",
    "    - ID Cluster (when visualising id against contra and ipsi)\n",
    "    \n",
    "    - Contra strings (when distplot failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
